{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2463,
     "status": "ok",
     "timestamp": 1589705099948,
     "user": {
      "displayName": "luca polenta",
      "photoUrl": "",
      "userId": "11661579579100361254"
     },
     "user_tz": -120
    },
    "id": "f-kOEMqSBP5O",
    "outputId": "c221e383-2808-4402-c2ff-8f448b6775d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports for array-handling and plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import csv\n",
    "import time\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# let's keep our keras backend tensorflow quiet\n",
    "import os\n",
    "\n",
    "# keras imports for the dataset and building our neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, datasets, optimizers\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impone ordinamento cartelle se hanno nomi di lunghezza diversa\n",
    "def classificator (directory):\n",
    "    childDirectories = next(os.walk(directory))[1]\n",
    "    for x in range(len(childDirectories)):\n",
    "        childDirectories[x]=int(childDirectories[x])\n",
    "    childDirectories.sort()\n",
    "    for x in range(len(childDirectories)):\n",
    "        childDirectories[x]=str(childDirectories[x])\n",
    "    return childDirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREAMBOLO:\n",
    "# 1. versione del dataset\n",
    "# 2. risorse (CPU/GPU)\n",
    "# 3. augmentation sul dataset di train e/o di test\n",
    "# 4. early stopping o meno\n",
    "\n",
    "# IMPOSTO MACROPARAMETRI E VARIABILI GLOBALI\n",
    "img_width, img_height = 32, 32\n",
    "epoche = 15\n",
    "batch_size = 100\n",
    "split_per_validazione = 0.15\n",
    "\n",
    "# 1. versione del dataset\n",
    "# settare 'sceltaDataset' come \"10RandomClasses\", \"10PoorestClasses\" o \"43Classes\"\n",
    "sceltaDataset = \"43Classes\"\n",
    "\n",
    "# 2. risorse (CPU/GPU)\n",
    "# settare 'programmatore' come \"LN\" per impostare le GPU, altrimenti qualsiasi altro modo per settare le CPU\n",
    "programmatore = \"LP\"\n",
    "\n",
    "# 3. augmentation sul dataset di train e/o di test\n",
    "# Se desideri l'augmentation del train o nel test imposta trainAg e/o testAg come 'SI'\n",
    "trainAg = 'SI'\n",
    "testAg = 'SI'\n",
    "\n",
    "# 4. early stopping o meno\n",
    "# Se desideri earlyStopping imposta la variabile a 'SI'\n",
    "earlyStopping = 'SI'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome Addestramento:\n",
      "PersonalCNN-43Classes-15Epoche-EarlyStoppingSI-TrainAgSI-TestAgSI\n"
     ]
    }
   ],
   "source": [
    "#CONTROLLI VARI\n",
    "\n",
    "#CONTROLLO E SETTAGGIO DEL DATASET:\n",
    "if sceltaDataset == \"10RandomClasses\":\n",
    "    numeroClassi = 10\n",
    "    origine = 'datasets/TrafficSignClassification-10RandomClasses'\n",
    "    nb_train_samples = 33000\n",
    "    nb_test_samples = 3300\n",
    "elif sceltaDataset == \"10PoorestClasses\":\n",
    "    numeroClassi = 10\n",
    "    origine = 'datasets/TrafficSignClassification-10PoorestClasses'\n",
    "    nb_train_samples = 4400\n",
    "    nb_test_samples = 720\n",
    "elif sceltaDataset == \"43Classes\":\n",
    "    numeroClassi = 43\n",
    "    origine = 'datasets/TrafficSignClassification-43Classes'\n",
    "    nb_train_samples = 65000\n",
    "    nb_test_samples = 9000\n",
    "else:\n",
    "    raise SystemExit(\"Dataset non riconosciuto\")\n",
    "\n",
    "#Imposto directory del dataset già decompresso dallo zip\n",
    "train_data_dir = origine+'/train'\n",
    "test_data_dir = origine+'/test'\n",
    "label_info_dir = origine+'/labels.csv'\n",
    "\n",
    "#Attivazione della CPU o della GPU\n",
    "if programmatore == \"LN\":\n",
    "    # for testing on GPU\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "else:\n",
    "    # for testing on CPU\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    \n",
    "\n",
    "#CREAZIONE PATH DI SALVATAGGIO COMUNE\n",
    "creoNomeAddestramento='PersonalCNN-'+sceltaDataset+'-'+str(epoche)+'Epoche-EarlyStopping'+earlyStopping+'-TrainAg'+trainAg+'-TestAg'+testAg\n",
    "pathSalvaModello=creoNomeAddestramento+'.h5'\n",
    "pathStampaModello='models/modelloDi'+sceltaDataset+'.png' \n",
    "    \n",
    "    \n",
    "#IMPOSTO L'AUGMENTANTION:\n",
    "#Default:\n",
    "train_shear_range, test_shear_range = 0.0, 0.0\n",
    "train_zoom_range, test_zoom_range = 0.0, 0.0\n",
    "train_width_shift_range, test_width_shift_range = 0.0, 0.0\n",
    "train_height_shift_range, test_height_shift_range = 0.0, 0.0\n",
    "train_fill_mode, test_fill_mode = \"constant\", \"constant\" #riempe i contorni in caso di modifica, messo costant così è nero\n",
    "#Attivazione augmentation se richiesta\n",
    "if trainAg == 'SI':\n",
    "    train_shear_range=0.15 #Distorsione angolare. Ne distorce un po' la forma, quindi la tengo\n",
    "    train_zoom_range=0.15 #Zoom da applicare alla foto. Ne distorce un po' la forma, quindi la tengo\n",
    "    train_width_shift_range=0.15 #spostamento orizzontale della foto per analizzarla anche da tagliata\n",
    "    train_height_shift_range=0.15 #spostamento verticale della foto per analizzarla anche da tagliata\n",
    "if testAg == 'SI':\n",
    "    test_shear_range=0.1\n",
    "    test_zoom_range=0.1\n",
    "    test_width_shift_range=0.1\n",
    "    test_height_shift_range=0.1\n",
    "\n",
    "    \n",
    "#IMPOSTO EARLYSTOPPING:\n",
    "if earlyStopping == 'SI':\n",
    "    #Implemento l'EarlyStopping\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n",
    "        baseline=None, restore_best_weights=False)\n",
    "    checkpoint_filepath = '/tmp/checkpoint'\n",
    "    epocheSalvataggio=5\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath, save_weights_only=True,\n",
    "            monitor='val_loss', save_freq=epocheSalvataggio,\n",
    "            save_best_only=True)\n",
    "    callback = [ TensorBoard(update_freq=521),\n",
    "                    EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "                    ModelCheckpoint(\"results/\"+pathSalvaModello, save_best_only=True), ]\n",
    "else:\n",
    "    callback = None\n",
    "\n",
    "\n",
    "print(\"Nome Addestramento:\")\n",
    "print(creoNomeAddestramento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCYbECUe9F7x"
   },
   "outputs": [],
   "source": [
    "def make_train_generator():\n",
    "    # Configurazione di augmentation per il training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        validation_split=split_per_validazione, #Quanto deve splittare il train per creare la validation\n",
    "        shear_range=train_shear_range,\n",
    "        zoom_range=train_zoom_range,\n",
    "        width_shift_range=train_width_shift_range,\n",
    "        height_shift_range=train_height_shift_range,\n",
    "        fill_mode=train_fill_mode,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False\n",
    "        #rotation_range=20, #Rotazione massima, espressa in intero. Disattiva perché i cartelli non si trovano ruotati\n",
    "        )\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=int(nb_train_samples*(1-split_per_validazione)),\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "    return train_generator\n",
    "\n",
    "def make_validation_generator():\n",
    "    # Configurazione di augmentation per il training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        validation_split=split_per_validazione, #Quanto deve splittare il train per creare la validation\n",
    "        shear_range=train_shear_range,\n",
    "        zoom_range=train_zoom_range,\n",
    "        width_shift_range=train_width_shift_range,\n",
    "        height_shift_range=train_height_shift_range,\n",
    "        fill_mode=train_fill_mode,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False\n",
    "        #rotation_range=20, #Rotazione massima, espressa in intero. Disattiva perché i cartelli non si trovano ruotati\n",
    "        )\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=int(nb_train_samples*split_per_validazione),\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "    return validation_generator\n",
    "\n",
    "def make_test_generator():\n",
    "    # Configurazione di augmentation per il test (solo rescaling nel caso non si voglia augmentation)\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=test_shear_range,\n",
    "        zoom_range=test_zoom_range,\n",
    "        width_shift_range=test_width_shift_range,\n",
    "        height_shift_range=test_height_shift_range,\n",
    "        fill_mode=test_fill_mode,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False\n",
    "        #rotation_range=20, #Rotazione massima, espressa in intero. Disattiva perché i cartelli non si trovano ruotati\n",
    "        )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=nb_test_samples,\n",
    "        class_mode=\"categorical\")\n",
    "    return test_generator\n",
    "\n",
    "#IMPORTANTE: PER MAGGIOR INFO SULL'AUGMENTATION DELLA IMAGEDATAGENERATOR, E' RIPORTATO IL LINK:\n",
    "#https://fairyonice.github.io/Learn-about-ImageDataGenerator.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo i nomi delle classi\n",
    "with open(label_info_dir, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "#elementi le prime entry che non sono dati utili\n",
    "data.pop(0)\n",
    "data.pop(0)\n",
    "listaNomiClassi = [];\n",
    "for i in range(len(data)):\n",
    "    #Divido la riga per poi prendere l'elemento che mi serve\n",
    "    rigaInEsame = data[i][0].split(\";\")\n",
    "    listaNomiClassi+=[rigaInEsame[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import del dataset usando tf.data.Dataset\n",
    "#train_dataset = tf.data.Dataset.from_generator(make_train_generator, (tf.float32, tf.float32))\n",
    "#validation_dataset = tf.data.Dataset.from_generator(make_validation_generator, (tf.float32, tf.float32))\n",
    "test_dataset = tf.data.Dataset.from_generator(make_test_generator, (tf.float32, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "#ricavare immagini e label dai dataset creati con i generator\n",
    "#for images, labels in train_dataset.take(1):\n",
    "#    X_train = images.numpy()\n",
    "#    Y_train = labels.numpy()\n",
    "    \n",
    "#for images, labels in validation_dataset.take(1):\n",
    "#    X_valid = images.numpy()\n",
    "#    Y_valid = labels.numpy()\n",
    "    \n",
    "for images, labels in test_dataset.take(1):\n",
    "    X_test = images.numpy()\n",
    "    Y_test = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HISTOGRAM REPRESENTATION\n",
    "#preliminari: conversione da one-hot-encoding a interi per visionare il numero di sample per dataset\n",
    "#y_train = np.empty(len(Y_train),dtype=int)\n",
    "#y_valid = np.empty(len(Y_valid),dtype=int)\n",
    "y_test = np.empty(len(Y_test),dtype=int)\n",
    "#for j in range(len(Y_train)):\n",
    "#    y_train[j]=(np.where(Y_train[j]==1)[0][0])\n",
    "\n",
    "#for j in range(len(Y_valid)):\n",
    "#    y_valid[j]=(np.where(Y_valid[j]==1)[0][0])\n",
    "    \n",
    "for j in range(len(Y_test)):\n",
    "    y_test[j]=(np.where(Y_test[j]==1)[0][0])\n",
    "\n",
    "#Quest'ultima cosa serve per la stampa finale\n",
    "immaginiPerLaStampaFinale=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHr2hSNpBuDq"
   },
   "outputs": [],
   "source": [
    "# Creazione un modello di addestramento sequenziale\n",
    "def model_sequential():\n",
    "#per usare leaky relu: activation=tf.nn.leaky_relu\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size=(7, 7),activation=tf.nn.leaky_relu ,input_shape=(img_width, img_height, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32,kernel_size=(5, 5),activation=tf.nn.leaky_relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3),activation=tf.nn.leaky_relu))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=tf.nn.leaky_relu))\n",
    "    model.add(Dense(numeroClassi, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 78,571\n",
      "Trainable params: 78,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nostroModello = model_sequential()\n",
    "nostroModello.summary()\n",
    "#tf.keras.utils.plot_model(nostroModello, to_file=pathStampaModello)\n",
    "#per usare RMSProp: optimizer=tf.keras.optimizers.RMSprop(lr=0.0001)\n",
    "nostroModello.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modello_cartelli = load_model(\"results/\"+pathSalvaModello, custom_objects={'leaky_relu': tf.nn.leaky_relu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.3113e-06 - accuracy: 1.0000\n",
      "Tempo d'addestramento in secondi:\n",
      "0.1676654815673828\n",
      "Tempo d'addestramento in ore-minuti-secondi-scartoRimanente:\n",
      "00:00:00.17\n"
     ]
    }
   ],
   "source": [
    "#CALCOLO IL TEMPO DI ADDESTRAMENTO\n",
    "t0 = time.time()\n",
    "\n",
    "loss_and_metrics = modello_cartelli.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "t1 = time.time()\n",
    "hours, rem = divmod(t1-t0, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "print(\"Tempo d'addestramento in secondi:\")\n",
    "print (t1 - t0)\n",
    "print(\"Tempo d'addestramento in ore-minuti-secondi-scartoRimanente:\")\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 1.311301275563892e-06\n",
      "Test Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "# Uso l'addestramento appena fatto per calcolare la loss e l'accuratezza sul test\n",
    "#modello_cartelli = load_model(\"results/\"+pathSalvaModello)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4553,
     "status": "ok",
     "timestamp": 1589651890288,
     "user": {
      "displayName": "luca polenta",
      "photoUrl": "",
      "userId": "11661579579100361254"
     },
     "user_tz": -120
    },
    "id": "xWN6BQr7UwPm",
    "outputId": "0e3fdb3d-1b1b-41db-c5bf-355e9b25b04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1  classified correctly\n",
      "0  classified incorrectly\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Le prossime predizioni sono giuste\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Digit: '0' corrisponde a 'Speed limit (20km/h)'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x1008 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Le prossime predizioni sono sbagliate\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creazione delle predizioni sul test set sulla base del modello caricato\n",
    "predicted_classes = modello_cartelli.predict_classes(X_test)\n",
    "\n",
    "# Distinguo cosa è stato predetto bene e cosa no\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "# adapt figure size to accomodate 18 subplots\n",
    "plt.rcParams['figure.figsize'] = (7,14)\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "print(\"\\n------------------------------------------------\\n\")\n",
    "print(\"Le prossime predizioni sono giuste\")\n",
    "print(\"\\n------------------------------------------------\\n\")\n",
    "\n",
    "listaClassiCheVerrannoStampate = []\n",
    "# Stampa delle 9 predizioni corrette\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    #Creo la lista di classi e valori che verranno stampate\n",
    "    valoreDigits=predicted_classes[correct]\n",
    "    nomeDigits=listaNomiClassi[valoreDigits]\n",
    "    if [valoreDigits, nomeDigits] not in listaClassiCheVerrannoStampate :\n",
    "        listaClassiCheVerrannoStampate+=[[valoreDigits, nomeDigits]]\n",
    "\n",
    "    #Stampa classica delle digits\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(immaginiPerLaStampaFinale[correct], interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted: {}, Truth: {}\".format(predicted_classes[correct],\n",
    "                                        y_test[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "#Prima stampo le classi presenti, con la corrispondente digits in ordine di digits\n",
    "for i in range(numeroClassi):\n",
    "    for j in range(len(listaClassiCheVerrannoStampate)):\n",
    "        if listaClassiCheVerrannoStampate[j][0]==i:\n",
    "            print(\"Digit: '{}' corrisponde a '{}'\".format(listaClassiCheVerrannoStampate[j][0], \n",
    "                                                          listaClassiCheVerrannoStampate[j][1]))\n",
    "            \n",
    "#Stampo i cartelli\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n------------------------------------------------\\n\")\n",
    "print(\"Le prossime predizioni sono sbagliate\")\n",
    "print(\"\\n------------------------------------------------\\n\")\n",
    "\n",
    "listaClassiCheVerrannoStampate = []\n",
    "# Stampa delle 9 predizioni incorrette\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    #Creo la lista di classi e valori che verranno stampate\n",
    "    valoreDigits=predicted_classes[incorrect]\n",
    "    nomeDigits=listaNomiClassi[valoreDigits]\n",
    "    if [valoreDigits, nomeDigits] not in listaClassiCheVerrannoStampate :\n",
    "        listaClassiCheVerrannoStampate+=[[valoreDigits, nomeDigits]]\n",
    "    valoreDigits=y_test[incorrect]\n",
    "    nomeDigits=listaNomiClassi[valoreDigits]\n",
    "    if [valoreDigits, nomeDigits] not in listaClassiCheVerrannoStampate :\n",
    "        listaClassiCheVerrannoStampate+=[[valoreDigits, nomeDigits]]\n",
    "\n",
    "    plt.subplot(6,3,i+10)\n",
    "    plt.imshow(immaginiPerLaStampaFinale[incorrect], interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted {}, Truth: {}\".format(predicted_classes[incorrect], \n",
    "                                       y_test[incorrect]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "#Prima stampo le classi presenti, con la corrispondente digits in ordine di digits\n",
    "for i in range(numeroClassi):\n",
    "    for j in range(len(listaClassiCheVerrannoStampate)):\n",
    "        if listaClassiCheVerrannoStampate[j][0]==i:\n",
    "            print(\"Digit: '{}' corrisponde a '{}'\".format(listaClassiCheVerrannoStampate[j][0], \n",
    "                                                          listaClassiCheVerrannoStampate[j][1]))\n",
    "            \n",
    "#Stampo i cartelli\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = tf.math.confusion_matrix(y_test, predicted_classes, num_classes=numeroClassi)\n",
    "tf.print(confusion_matrix, summarize=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c41ffc150cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"elemento con più errori è in posizione [\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"][\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"] con numero errori pari a:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "# ricerca dell'elemento con più errori (se può servire)\n",
    "row = 0\n",
    "col = 0\n",
    "item = 0\n",
    "for r in range(len(confusion_matrix)):\n",
    "    for c in range(len(confusion_matrix[r])):\n",
    "        if (r != c and confusion_matrix[r][c] > item):\n",
    "            item = confusion_matrix[r][c]\n",
    "            row = r\n",
    "            col = c\n",
    "print(\"elemento con più errori è in posizione [\", row, \"][\", col, \"] con numero errori pari a:\",item.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "plt.matshow(confusion_matrix.numpy(), cmap=plt.cm.gray)\n",
    "#plt.savefig('models/confusion_matrix'+sceltaDataset+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nome Addestramento:\")\n",
    "print(creoNomeAddestramento)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMBwFUuCjAKgCnxbrZU2XkX",
   "collapsed_sections": [],
   "mount_file_id": "1trthuiRVxQ1ls3XHN3Vr5gJyxFZHEjwP",
   "name": "HW5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
